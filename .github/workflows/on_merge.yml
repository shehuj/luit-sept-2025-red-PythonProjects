# This worklow will check for the presence of README.md and .gitignore files.
# Then install Python dependencies, run tests and lint with a variety of Python versions.
# For more information see: https://docs.github.com/en/actions/automating-builds-and-tests/building-and-testing-python

name: Run tests and Check required files

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]

jobs:
  build:

    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.9"]

    steps:
    - uses: actions/checkout@v4
    
    - name: Check required files
      run: | 
        python 02/tests/test_check_required_files.py

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v3
      with:
        python-version: ${{ matrix.python-version }}

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        python -m pip install flake8 pytest
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

    - name: Lint with flake8
      run: |
        # stop the build if there are Python syntax errors or undefined names
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        # exit-zero treats all errors as warnings. The GitHub editor is 127 chars wide
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics

    - name: Configure AWS credentials
      if: steps.file_audit.outcome == 'success'
      uses: aws-actions/configure-aws-credentials@v2
      with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

    - name: Log enriched audit to CloudWatch (prod)
      if: steps.file_audit.outcome == 'success'
      run: |
          LOG_GROUP="/github-actions/required-files-checker/prod"

          # Use a timestamp without colons for the log stream name (valid pattern: no ':' or '*')
          LOG_STREAM=$(date -u +"%Y-%m-%dT%H-%M-%SZ")

          # GitHub / repo context
          REPO="${GITHUB_REPOSITORY}"
          BRANCH="${GITHUB_REF##*/}"
          EVENT="${GITHUB_EVENT_NAME}"
          SHA="${GITHUB_SHA}"
          ACTOR="${GITHUB_ACTOR}"

          # Load the audit context JSON from earlier
          CONTEXT=$(cat audit_output.json)

          echo "Logging to: group=$LOG_GROUP, stream=$LOG_STREAM"
          echo "Context: $CONTEXT"

          # Create log group if missing (ignore error)  
          aws logs create-log-group --log-group-name "$LOG_GROUP" || true

          # Create log stream
          aws logs create-log-stream --log-group-name "$LOG_GROUP" --log-stream-name "$LOG_STREAM"

          # Compose a JSON object combining everything
          inner_message=$(jq -n \
            --arg repo "$REPO" \
            --arg branch "$BRANCH" \
            --arg event "$EVENT" \
            --arg sha "$SHA" \
            --arg actor "$ACTOR" \
            --arg ctx "$CONTEXT" \
            '{
              repository: $repo,
              branch: $branch,
              event: $event,
              commit_sha: $sha,
              actor: $actor,
              audit: ($ctx | fromjson)
            }'
          )

          # Prepare for AWS CLI
          timestamp_ms=$(date +%s%3N)
          # Escape the JSON as a string for the `message` field
          msg_escaped=$(echo "$inner_message" | jq -Rs '.')

          aws logs put-log-events \
            --log-group-name "$LOG_GROUP" \
            --log-stream-name "$LOG_STREAM" \
            --log-events timestamp=$timestamp_ms,message="$msg_escaped"


    - name: Test with pytest
      run: |
        pytest 02/tests/